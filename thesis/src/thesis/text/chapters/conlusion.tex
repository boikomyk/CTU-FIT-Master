%---------------------------------------------------------------
\chapter{Conclusion}
\label{chap:conclusion}
%---------------------------------------------------------------
This thesis considers the sequential inference of state-space models using the Bayesian framework. The principle of the state-space representation itself approaches to modeling, and examples of use were examined in detail. Also considered was the very concept of Bayesian statistical inference, as finding the posterior distribution of states based on a sequence of observations as well as initial knowledge of the states called prior density. This included consideration of the most popular and widespread implementation of Bayesian filtering, filters from the Kalman family. Starting with the theory of linear systems, possible nonlinearities in systems were also touched upon, including completely nonlinear systems, including the possibility of applying the Kalman filter in the context of nonlinearity, or rather its extended version, and the principle of this application itself. It also questioned the possible difficulties with the inference process associated with an under-specified model and, accordingly, how this might affect the efficiency of the KFs.

Further, separate attention was paid to an alternative, but no less popular technique of state filtering, the class of SMC filters, namely the PF, which, due to the very idea of approximately representing required distribution by random samples, was supposed to show itself more stable in the context of misspecified models. But still, it also requires the measurement model to be a well-defined probability density, which is not possible in all applications. Given the dependence of the PF filter on knowledge of the measurement model, a more flexible approach, called ABC, which just might be used to bypass this requirement, was also studied and discussed.

Thus was derived an ABC filter with an adaptive kernel, which stands on the rails of the SMC filter, but uses an already approximated likelihood function in the update step. The concept of kernel usage and several possible types of commonly used kernels were also discussed.

All of the above was a good theoretical basis before proceeding directly to the experimental part. The experiments were performed with multiple repetitions to obtain representative results, and three different models and all of the filters and their variations listed above were used in the experiment. As for the comparison of the filters themselves, comparing the PF filter and the standard filters from the Kalman family, it can be safely said that as the number of particles used increases, so does the computational complexity, but thus the final results are more accurate. As for the obtained ABC filter with the adaptive kernel, we can conclude that it does not introduce any additional computational complexity compared to the PF. It is also important to note the fact that, while the model is highly nonlinear, the extended version of KF has a rather high computational cost for calculating the Jacobian matrix.

As for the performance and robustness of the filters themselves after the experiments, it can be safely stated the following theses. As for experiments on well-specified models, provided guaranteed linearity, and when both state and measurement models are linear with zero mean Gaussian noise, in this case, KF is still the best linear estimator, which showed the best results and, unlike other filters, is the cheapest in use. In the case of a nonlinear but well-defined model, it is better to use PF, as opposed to EKF, which, when one of the steps, either prediction or update, is highly nonlinear, will have relatively poor performance. It is also worth noting that the ABC filter with different kernels showed itself very competitively, but all were noticeably inferior to both the KF filter and the PF. In general, it can be argued that the results of the experiments revealed that the ABC filter is not overly sensitive to kernel choice, regardless of model specification.

Regarding experiments with misspecified models, and more specifically, in the context of the misspecified measurement model, the ABC filter, regardless of the kernel choice, proved unsurpassed. It is also pertinent to emphasize the particular robustness of ABC filters in different realizations of heavy-tailed noise.

As for possible ideas and extensions for future works, one of the main directions will be formulating the adaptive kernel tuning to multiple dimensions. For as already noted, within this thesis, most of the models had multidimensional measurement values, but the procedure of tuning itself was done in the context of one-dimensional kernels, handling multidimensional data in a coordinate-wise manner. The consequence of this is that the individual measurement vector elements are assumed to be independent. Also, a good solution for future work would be to take both more complex and as simple models as possible to make a comparison still in this context. And, of course, expanding the list of filters used in the experiments would be nice.